---
prev:
  text: 'Введение в Статистику'
  link: '/statistics/01_intro_to_statistics'
next:
  text: 'Теория оценок'
  link: '/statistics/03_evaluation_theory'
outline: deep
---

# Эмпирическая функция распределения

>Введем обозначения:
> - $X_1, ..., X_n$ - случайные величины
> - $x_1, ..., x_n$ - реализации случайных величин

Введем эмпирическую функцию распределения $F_n (t)$

$$ \hat{F}_n (t) = \frac{\sum_{i=1}^n Ind(X_i \leq t)}{n} $$
$$ \hat{F}_n \in \{0; \frac{1}{n}; ...; 1\} - \text{всего n+1 значение}$$
$$ F_\xi (t) = P(x \leq t) $$
Покажем, что ЭФР работает:
$$ P\left( \hat{F}_n (t) = \frac{k}{n} \right) = C_n^k (F_\xi (t))^k (1 - F_\xi (t))^{n-k} $$
Тут $F_\xi(t)$ обозначает вероятность того, что СВ не превзойдет значение t.

**Выводы.**

**Утверждение 1.** ЭФР в фиксированной точке t сходится по вероятности к значению истинной(теоретической) функции распределения наблюдаемой выборки.
> [!info] Сходимость по вероятности
> Последовательность СВ $\xi_1 ... \xi_n$ сходится по вероятности, если:
> $$ \lim_{n \to \infty}  P( |\xi_n - \xi| > \varepsilon ) = 0 $$

Для ЭФР:
$$ P( |\hat{F}_n(t) - F(t)| > \varepsilon) \to 0 $$

**Доказательство.**

> [!info] Неравенство Чебышева
> $$ P(|\xi - E \xi| > \varepsilon) < \frac{D \xi}{\varepsilon^2} $$

$$ E \hat{F_{n}} (t) = \sum_{i = 1}^n \frac{P (x_i \leq t)}{n} = n \cdot \frac{P (x_1 \leq t)}{n} = P (x_1 \leq t) = F_\xi (t)$$
$$ D \hat{F}_n (t) = E( \hat{F}_n (t) - E \hat{F}_n (t)) ^2 = \frac{F_{\xi}(1-F_{\xi})}{n} $$
Запишем неравенство Чебышева:
$$ P(|\hat{F}_n (t) - F_\xi (t)| > \varepsilon ) \leq \frac{F_\xi (t) (1 - F_\xi (t))}{n \cdot \varepsilon^2} $$
**Примечание:** Это неравенство можно усилить!

> [!info] Сходимость почти наверное
> Последовательность $\xi_1 ... \xi_n$ сходиться "почти наверное" у СВ $\xi$, если
> $$ P(\lim_{n \to \infty} \xi_n = \xi ) = 1$$

## Теорема Гливенко-Контелли

ЭФР $F_n (t)$ сходится с вероятностью 1 к теоретической $F_\xi (t)$ с ростом обьема выборки
**Доказательство**
Для последовательности выполняется ЦПТ, если
$$ P \left(  \frac{\sum \xi_i - E \sum \xi_i}{\sqrt{ D \sum \xi_i })}  \leq t \right) \to \Phi(t) $$
Если взять $t_1 = -3 \sigma, t_2 = 3 \sigma$, равенство ниже будет примерно выполняться:
$$ P\left( t_{1} \leq \frac{\hat{F}_{n}-F_{\xi}(t)}{\sqrt{ \left( \frac{F_{\xi}(t)(1-F_{\xi}(t))}{n} \right)}} \leq t_{2} \right) \sim \int_{t_{1}}^{t_{2}} e^{-x^2/2} dx$$

 из этого можно сказать, что:
$$F_\xi(x) - \frac{a_1}{\sqrt{n} }\leq \hat{F}_n(x) \leq F_\xi (x) - \frac{a_2}{\sqrt{n}} $$
$$ |F_\xi (x) - \hat{F}_n(x)| \leq \max ( \frac{a_1}{\sqrt{n}} ; \frac{a_{2}}{\sqrt{n}} ) $$
Примечание: Таким образом мы можем оценивать интервалы сходимости!

## Теорема Колмогорова

Пусть $F(x)$ - непрерывная функция распределения
Тогда для $D_n = \sup_{x} |\hat{F}_n(x)-F(x)|$:
$$ P( \sqrt{ n }D_{n} \leq t) \to K(t) = \sum_{j=1}^\infty (-1)^j e^{-j^2t^2} \text{при n} \to \infty $$

## Теорема Смирнова

> $X_1 ... X_n, Y_1 ... Y_m$ - некоторый набор случайных величин
> $F(x)$ - непрерывная функция распределения

$$ D_{n, m} = \sup_x |F_n (x) - F_m (x)| $$
$$P\left(  \sqrt{ \frac{nm}{n+m} } \leq t  \right) \to K(t)$$
Таким образом мы можем оценивать, из одного СВ распределения или нет
