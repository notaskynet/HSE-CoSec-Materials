---
next:
  text: 'К содержанию'
  link: '/ml/ml_index'
prev: false
---

# Оценивание обучающей способности модели

Если ошибка на новых данных сильно больше ошиьки на старых данных(на тесстовой выборке), то такая ситуация называется **переобучением модели**.
![1 Проблема переобучения при восстановлении зависимостей по эипирическим  данным и основные задачи исследования](https://studfile.net/html/2706/278/html_mYXB48QqfA.xrss/img-QXgepo.png)

### Отложенная выборка (hold-out set)
![alt](https://i.imgur.com/kkBTGMH.png)

### Кросс-валидация
*Идея*: Разделяем выборку на несколько подвыборок, и поочередно выкидываем по одной, на остальных обучаем. Потом на выкинутой выборки тестируем модуль.
При $k=l \implies$ Leavr-One-Out

*Какую модель использовать?*
1) $x \to \frac{1}{k} \sum_{i=1}^k a_{i} (x)$
2) Обучить финальну выборку на всех данных

*Замечания*
1) Если $\ell$ большой, то кросс-валидация вряд ли поможет(выброс одного объекта будет не так значителен)
2) Кросс-валидация требует $k$ раз обучить модель
